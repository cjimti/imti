<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>JSON on IMTI</title>
    <link>https://imti.co/tags/json/</link>
    <description>Recent content in JSON on IMTI</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Jul 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://imti.co/tags/json/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>High Traffic JSON Data into Elasticsearch on Kubernetes</title>
      <link>https://imti.co/post-json-elasticsearch-kubernetes/</link>
      <pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://imti.co/post-json-elasticsearch-kubernetes/</guid>
      <description>&lt;p&gt;IOT devices, Point-of-Sale systems, application events or any client that sends data destined for indexing in Elasticsearch often need to send and forget, however, unless that data is of low value there needs to be assurance that arrives at its final destination. Back-pressure and database outages can pose a considerable threat to data integrity.&lt;/p&gt;&#xA;&lt;aside class=&#34;toc&#34;&gt;&#xA;    &lt;header&gt;&#xA;        &lt;h2&gt;Contents&lt;/h2&gt;&#xA;    &lt;/header&gt;&#xA;    &lt;nav id=&#34;TableOfContents&#34;&gt;&#xA;  &lt;ul&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#background&#34;&gt;Background&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#overview&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#development-environment&#34;&gt;Development Environment&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#the-project-namespace&#34;&gt;the-project Namespace&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#the-project-weather-wx-data&#34;&gt;The Project: Weather (wx) Data&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#rxtx-for-store-and-forward&#34;&gt;rxtx for Store-and-Forward&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#wx-rxtx-service&#34;&gt;wx-rxtx Service&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#wx-rxtx-statefulset&#34;&gt;wx-rxtx StatefulSet&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#rtbeat-to-collect-buffer-and-publish&#34;&gt;rtBeat to Collect, Buffer and Publish&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#wx-rtbeat-service&#34;&gt;wx-rtbeat Service&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#wx-rtbeat-configmap&#34;&gt;wx-rtbeat ConfigMap&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#wx-rtbeat-deployment&#34;&gt;wx-rtbeat Deployment&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#client-simulation--kubernetes-cron&#34;&gt;Client Simulation / Kubernetes Cron&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#performance&#34;&gt;Performance&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#port-forwarding--local-development&#34;&gt;Port Forwarding / Local Development&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#reference&#34;&gt;Reference&lt;/a&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/nav&gt;&#xA;&lt;/aside&gt;&#xA;&#xA;&#xA;&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;&#xA;&lt;p&gt;High availability and high performance often mean burdensome complexity. Data replication, application, network and infrastructure redundancy, anything we can do to avoid a single point of failure. However, what happens when one of those points do fail? Alternatively, a cascade of problems causing slowdowns and back pressure builds to constant far too high for indexing to catch up?&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
