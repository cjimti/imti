<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data on IMTI</title>
    <link>http://localhost:1313/tags/data/</link>
    <description>Recent content in Data on IMTI</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 30 Aug 2020 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/data/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Advanced Platform Development with Kubernetes</title>
      <link>http://localhost:1313/kubernetes-platform-book/</link>
      <pubDate>Sun, 30 Aug 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/kubernetes-platform-book/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve been distracted for over a year now, writing a (~500 page) end-to-end tutorial on constructing data-centric platforms with Kubernetes. The book is titled &amp;ldquo;&lt;a href=&#34;https://amzn.to/3hAZUvx&#34;&gt;Advanced Platform Development with Kubernetes: Enabling Data Management, the Internet of Things, Blockchain, and Machine Learning&lt;/a&gt;&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;A little more than a year ago, Apress reached out and asked if I would write a book on Kubernetes for them, mirroring the wide range of projects I develop (and write about) for my clients. I have been building data-centric platforms for almost twenty years, spanning everything from my early days on the aggregation of massive volumes of international log files for Disney to fan-driven location data for Nine Inch Nails. And in the last decade, retailers with point-of-sale, logistics, and inventory systems, marketers leveraging social media metrics, fleet operators with demanding telematics platforms, and manufacturers with advanced IIoT (industrial internet of things) networks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kafka on Kubernetes</title>
      <link>http://localhost:1313/kafka-kubernetes/</link>
      <pubDate>Tue, 25 Sep 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/kafka-kubernetes/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://kafka.apache.org/&#34;&gt;Kafka&lt;/a&gt; is a fast, horizontally scalable, fault-tolerant, message queue service. &lt;a href=&#34;https://kafka.apache.org/&#34;&gt;Kafka&lt;/a&gt; is used for building real-time data pipelines and streaming apps.&lt;/p&gt;&#xA;&lt;p&gt;There are a few &lt;a href=&#34;https://helm.sh/&#34;&gt;Helm&lt;/a&gt; based installers out there including the official Kubernetes &lt;a href=&#34;https://github.com/helm/charts/tree/master/incubator/kafka&#34;&gt;incubator/kafka&lt;/a&gt;. However, in this article, I walk through applying a surprisingly small set of Kubernetes configuration files needed to stand up high performance, highly available Kafka. Manually applying Kubernetes configurations gives you a step-by-step understanding of the system you are deploying and limitless opportunities to customize.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Elasticsearch Essential Queries</title>
      <link>http://localhost:1313/elasticsearch-essential-queries/</link>
      <pubDate>Thu, 26 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elasticsearch-essential-queries/</guid>
      <description>&lt;p&gt;The following is an overview for querying &lt;a href=&#34;https://www.elastic.co/products/elasticsearch&#34;&gt;Elasticsearch&lt;/a&gt;. Over the years I have tried to assemble developer notes for myself and my team on a variety of platforms, languages and frameworks, a type of cheat-sheet but with context, not a comprehensive how-to, but a decent 15-minute overview of the features we are most likely to implement in a given iteration.&lt;/p&gt;&#xA;&lt;p&gt;Explore the &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/guide/current/search-in-depth.html&#34;&gt;Elasticsearch official documentation&lt;/a&gt;: &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/guide/current/search-in-depth.html&#34;&gt;Search in Depth&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;aside class=&#34;toc&#34;&gt;&#xA;    &lt;header&gt;&#xA;        &lt;h2&gt;Contents&lt;/h2&gt;&#xA;    &lt;/header&gt;&#xA;    &lt;nav id=&#34;TableOfContents&#34;&gt;&#xA;  &lt;ul&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#motivation&#34;&gt;Motivation&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#following-along-with-elasticsearch-and-kubernetes&#34;&gt;Following Along with Elasticsearch and Kubernetes&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#vocabulary&#34;&gt;Vocabulary&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#basic-crud-api&#34;&gt;Basic CRUD API&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#delete-an-index&#34;&gt;Delete an Index&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#create-an-index&#34;&gt;Create an Index&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#create-or-update-a-document-upsert&#34;&gt;Create or Update a Document (Upsert)&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#get-a-document&#34;&gt;Get a Document&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#mappings-types-and-metadata&#34;&gt;Mappings, Types and Metadata&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#get-mapping&#34;&gt;Get Mapping&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#create-a-mapping&#34;&gt;Create a Mapping&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#searching&#34;&gt;Searching&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#range&#34;&gt;Range&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#filtering&#34;&gt;Filtering&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#aggregations&#34;&gt;Aggregations&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#counts&#34;&gt;Counts&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#averages-minimums-and-maximums&#34;&gt;Averages, Minimums and Maximums&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#percentile&#34;&gt;Percentile&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#percent-by-rank&#34;&gt;Percent by Rank&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#percent-by-rank-interval&#34;&gt;Percent by Rank Interval&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#resources&#34;&gt;Resources&lt;/a&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/nav&gt;&#xA;&lt;/aside&gt;&#xA;&#xA;&#xA;&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;&#xA;&lt;p&gt;My team and I work with a lot of SQL-based data, from MySQL, SQLite and even our large Cassandra cluster, however, our reporting systems are built on &lt;a href=&#34;https://www.elastic.co/products/elasticsearch&#34;&gt;Elasticsearch&lt;/a&gt;. Transitioning our thinking from SQL to the &lt;a href=&#34;https://blog.parse.ly/post/1691/lucene/&#34;&gt;Lucene&lt;/a&gt; syntax on occasion requires hitting the docs. However, most technical documentation is either for getting started or gives you every variation of every feature, which is great when you are neck deep and need a specific problem solved.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Remote Query Elasticsearch on Kubernetes</title>
      <link>http://localhost:1313/remote-query-kubernetes-elasticsearch/</link>
      <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/remote-query-kubernetes-elasticsearch/</guid>
      <description>&lt;p&gt;Developing on our local workstations has always been a conceptual challenge for my team when it comes to remote data access.  Local workstation-based development of services that intend to connect to a wide range of remote services that may have no options for external connections poses a challenge. Mirroring the entire development environment is possible in many cases, just not practical.&lt;/p&gt;&#xA;&lt;p&gt;In days before Kubernetes, writing code in IDEs on our local workstation meant we had only a few options for developing server-side-API-style services that needed to connect to a database. We could set up a database server on our local workstation manually or use packages like &lt;a href=&#34;https://www.mamp.info/en/&#34;&gt;MAMP&lt;/a&gt;/&lt;a href=&#34;http://www.wampserver.com/en/&#34;&gt;WAMP&lt;/a&gt;, or run big virtual servers managed with &lt;a href=&#34;https://www.vagrantup.com/&#34;&gt;Vagrant&lt;/a&gt;. Even after we got the database running, we needed a good set of data to work with, and that often meant asking a DBA or Sysadmin for SQL dumps from an environment in which we have no access.&lt;/p&gt;</description>
    </item>
    <item>
      <title>High Traffic JSON Data into Elasticsearch on Kubernetes</title>
      <link>http://localhost:1313/post-json-elasticsearch-kubernetes/</link>
      <pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post-json-elasticsearch-kubernetes/</guid>
      <description>&lt;p&gt;IOT devices, Point-of-Sale systems, application events or any client that sends data destined for indexing in Elasticsearch often need to send and forget, however, unless that data is of low value there needs to be assurance that arrives at its final destination. Back-pressure and database outages can pose a considerable threat to data integrity.&lt;/p&gt;&#xA;&lt;aside class=&#34;toc&#34;&gt;&#xA;    &lt;header&gt;&#xA;        &lt;h2&gt;Contents&lt;/h2&gt;&#xA;    &lt;/header&gt;&#xA;    &lt;nav id=&#34;TableOfContents&#34;&gt;&#xA;  &lt;ul&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#background&#34;&gt;Background&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#overview&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#development-environment&#34;&gt;Development Environment&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#the-project-namespace&#34;&gt;the-project Namespace&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#the-project-weather-wx-data&#34;&gt;The Project: Weather (wx) Data&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#rxtx-for-store-and-forward&#34;&gt;rxtx for Store-and-Forward&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#wx-rxtx-service&#34;&gt;wx-rxtx Service&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#wx-rxtx-statefulset&#34;&gt;wx-rxtx StatefulSet&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#rtbeat-to-collect-buffer-and-publish&#34;&gt;rtBeat to Collect, Buffer and Publish&lt;/a&gt;&#xA;      &lt;ul&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#wx-rtbeat-service&#34;&gt;wx-rtbeat Service&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#wx-rtbeat-configmap&#34;&gt;wx-rtbeat ConfigMap&lt;/a&gt;&lt;/li&gt;&#xA;        &lt;li&gt;&lt;a href=&#34;#wx-rtbeat-deployment&#34;&gt;wx-rtbeat Deployment&lt;/a&gt;&lt;/li&gt;&#xA;      &lt;/ul&gt;&#xA;    &lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#client-simulation--kubernetes-cron&#34;&gt;Client Simulation / Kubernetes Cron&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#performance&#34;&gt;Performance&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#port-forwarding--local-development&#34;&gt;Port Forwarding / Local Development&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#reference&#34;&gt;Reference&lt;/a&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/nav&gt;&#xA;&lt;/aside&gt;&#xA;&#xA;&#xA;&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;&#xA;&lt;p&gt;High availability and high performance often mean burdensome complexity. Data replication, application, network and infrastructure redundancy, anything we can do to avoid a single point of failure. However, what happens when one of those points do fail? Alternatively, a cascade of problems causing slowdowns and back pressure builds to constant far too high for indexing to catch up?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kibana on Kubernetes</title>
      <link>http://localhost:1313/kibana-kubernetes/</link>
      <pubDate>Sun, 15 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/kibana-kubernetes/</guid>
      <description>&lt;p&gt;This guide walks through a process for setting up &lt;a href=&#34;https://www.elastic.co/products/kibana&#34;&gt;Kibana&lt;/a&gt; within a &lt;a href=&#34;http://localhost:1313/kubernetes-production-elasticsearch/#project-namespace&#34;&gt;namespace&lt;/a&gt; on a Kubernetes cluster. If you followed along with &lt;a href=&#34;http://localhost:1313/kubernetes-production-elasticsearch/&#34;&gt;Production Grade Elasticsearch on Kubernetes&lt;/a&gt; then aside from personal or corporate preferences, little modifications are necessary for the configurations below.&lt;/p&gt;&#xA;&lt;aside class=&#34;toc&#34;&gt;&#xA;    &lt;header&gt;&#xA;        &lt;h2&gt;Contents&lt;/h2&gt;&#xA;    &lt;/header&gt;&#xA;    &lt;nav id=&#34;TableOfContents&#34;&gt;&#xA;  &lt;ul&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#project-namespace&#34;&gt;Project Namespace&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#service&#34;&gt;Service&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#kibana-configmap&#34;&gt;Kibana ConfigMap&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#deployment&#34;&gt;Deployment&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#basic-auth-optional&#34;&gt;Basic Auth (Optional)&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#tls-certificate-optional&#34;&gt;TLS Certificate (Optional)&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#ingress&#34;&gt;Ingress&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#port-forwarding--local-development&#34;&gt;Port Forwarding / Local Development&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li&gt;&lt;a href=&#34;#resources&#34;&gt;Resources&lt;/a&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/nav&gt;&#xA;&lt;/aside&gt;&#xA;&#xA;&#xA;&lt;h2 id=&#34;project-namespace&#34;&gt;Project &lt;a href=&#34;http://localhost:1313/kubernetes-production-elasticsearch/#project-namespace&#34;&gt;Namespace&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;I use &lt;code&gt;the-project&lt;/code&gt; as a namespace for all my examples and testing. &lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/&#34;&gt;Kubernetes Namespaces&lt;/a&gt; are the main delimiter I use for security and organization. Configuration files are organized by project, and in Kubernetes, these projects are separated by namespace; therefore I always include a namespace configuration. There is no harm in asking Kubernetes to create a namespace that already exists; an error is returned confirming its existence.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Production Grade Elasticsearch on Kubernetes</title>
      <link>http://localhost:1313/kubernetes-production-elasticsearch/</link>
      <pubDate>Sat, 14 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/kubernetes-production-elasticsearch/</guid>
      <description>&lt;p&gt;Installing production ready, Elasticsearch 6.2 on Kubernetes requires a hand full of simple configurations. The following guide is a high-level overview of an installation process using Elastic&amp;rsquo;s &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/6.2/modules-node.html&#34;&gt;recommendations for best practices&lt;/a&gt;. The Github project &lt;a href=&#34;https://github.com/pires/kubernetes-elasticsearch-cluster&#34;&gt;kubernetes-elasticsearch-cluster&lt;/a&gt; is used for the Elastic Docker container and built to operate Elasticsearch with nodes dedicated as Master, Data, and Client/Ingest.&lt;/p&gt;&#xA;&lt;p&gt;The Docker container &lt;a href=&#34;https://github.com/pires/docker-elasticsearch&#34;&gt;docker-elasticsearch&lt;/a&gt;, a &amp;ldquo;Ready to use, lean and highly configurable Elasticsearch container image.&amp;rdquo; by &lt;a href=&#34;https://github.com/pires&#34;&gt;pires&lt;/a&gt; is sufficient for use in this guide. However, the &lt;a href=&#34;https://github.com/txn2/k8s-es&#34;&gt;txn2/k8s-es&lt;/a&gt; wraps it with a few minor preset environment variables to simplify configuration. I use the docker image &lt;a href=&#34;https://hub.docker.com/r/txn2/k8s-es/tags/&#34;&gt;txn2/k8s-es:v6.2.3&lt;/a&gt; in the examples below.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python Data Essentials - Matplotlib and Seaborn</title>
      <link>http://localhost:1313/python-data-essentials-matplotlib-seaborn/</link>
      <pubDate>Sun, 08 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python-data-essentials-matplotlib-seaborn/</guid>
      <description>&lt;p&gt;There is an overwhelming number of options for developers needing to provide data visualization. The most popular library for data visualization in Python is &lt;a href=&#34;https://matplotlib.org/&#34;&gt;Matplotlib&lt;/a&gt;, and built directly on top of Matplotlib is &lt;a href=&#34;https://seaborn.pydata.org/&#34;&gt;Seaborn&lt;/a&gt;. The Seaborn library is &amp;ldquo;tightly integrated with the &lt;a href=&#34;https://pydata.org/&#34;&gt;PyData&lt;/a&gt; stack, including support for &lt;a href=&#34;http://localhost:1313/python-data-essentials-numpy/&#34;&gt;numpy&lt;/a&gt; and &lt;a href=&#34;http://localhost:1313/python-data-essentials-pandas/&#34;&gt;pandas&lt;/a&gt; data structures and statistical routines from &lt;a href=&#34;https://www.scipy.org/&#34;&gt;scipy&lt;/a&gt; and &lt;a href=&#34;https://www.statsmodels.org/stable/index.html&#34;&gt;statsmodels&lt;/a&gt;.&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;This article is only intended to get you started with &lt;a href=&#34;https://matplotlib.org/&#34;&gt;Matplotlib&lt;/a&gt; and &lt;a href=&#34;https://seaborn.pydata.org/&#34;&gt;Seaborn&lt;/a&gt;. Both libraries have extensive and mature documentation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Webpage to PDF Microservice</title>
      <link>http://localhost:1313/webpage-to-pdf-microservice/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/webpage-to-pdf-microservice/</guid>
      <description>&lt;p&gt;I create a lot of data visualizations for clients, many of which are internal, portal-style websites that present data in real time, as well as give options for viewing reports from previous time-frames. PDFs are useful for data such as bank statements or any form of time-snapshot progress reporting. It is common for clients to want PDF versions generated on a regular basis for sharing through email or other technologies.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python Data Essentials - Pandas</title>
      <link>http://localhost:1313/python-data-essentials-pandas/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python-data-essentials-pandas/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pandas.pydata.org/&#34;&gt;Pandas&lt;/a&gt; bring Python a data type equivalent to super-charged spreadsheets. Pandas add two highly expressive data structures to Python, &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html&#34;&gt;Series&lt;/a&gt; and &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html&#34;&gt;DataFrame&lt;/a&gt;. Pandas &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html&#34;&gt;Series&lt;/a&gt; and &lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html&#34;&gt;DataFrame&lt;/a&gt;s provide a performant analysis and manipulation of “relational” or “labeled” data similar to relational database tables like MySQL or the rows and columns of Excel. &lt;a href=&#34;https://pandas.pydata.org/&#34;&gt;Pandas&lt;/a&gt; are great for working with time series data as well as arbitrary matrix data, and unlabeled data.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://pandas.pydata.org/&#34;&gt;Pandas&lt;/a&gt; leverage &lt;a href=&#34;http://localhost:1313/python-data-essentials-numpy/&#34;&gt;NumPy&lt;/a&gt; and if you are not familiar with this fundamental library for working with numbers, then I suggest you take a look at &lt;a href=&#34;http://localhost:1313/python-data-essentials-numpy/&#34;&gt;Python Data Essentials - NumPy&lt;/a&gt; to get a decent footing.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python Data Essentials - Numpy</title>
      <link>http://localhost:1313/python-data-essentials-numpy/</link>
      <pubDate>Sat, 16 Jun 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/python-data-essentials-numpy/</guid>
      <description>&lt;p&gt;Python is one of &lt;a href=&#34;https://dzone.com/articles/which-are-the-popular-languages-for-data-science&#34;&gt;The Most Popular Languages for Data Science&lt;/a&gt;, and because of this adoption by the &lt;a href=&#34;http://www.scipy-lectures.org/intro/intro.html#why-python&#34;&gt;data science&lt;/a&gt; community, we have libraries like &lt;a href=&#34;http://www.numpy.org/&#34;&gt;NumPy&lt;/a&gt;, &lt;a href=&#34;http://localhost:1313/python-data-essentials-pandas/&#34;&gt;Pandas&lt;/a&gt; and &lt;a href=&#34;http://localhost:1313/python-data-essentials-matplotlib-seaborn/&#34;&gt;Matplotlib&lt;/a&gt;. &lt;a href=&#34;http://www.numpy.org/&#34;&gt;NumPy&lt;/a&gt; at it&amp;rsquo;s core provides a powerful N-dimensional array objects in which we can perform linear algebra, &lt;a href=&#34;http://localhost:1313/python-data-essentials-pandas/&#34;&gt;Pandas&lt;/a&gt; give us data structures and data analysis tools, similar to working with a specialized database or powerful spreadsheets and finally &lt;a href=&#34;http://localhost:1313/python-data-essentials-matplotlib-seaborn/&#34;&gt;Matplotlib&lt;/a&gt; to generate plots, histograms, power spectra, bar charts, error charts and scatterplots to name a few.&lt;/p&gt;</description>
    </item>
    <item>
      <title>SQL Foundations</title>
      <link>http://localhost:1313/sql-select-joins-aliases/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/sql-select-joins-aliases/</guid>
      <description>&lt;p&gt;The following is an attempt at explaining the basics of an SQL query, and more importantly how I believe you can best think through them. All queries can be broken down into the basics of this declarative language.&lt;/p&gt;&#xA;&lt;p&gt;I recently helped a co-worker read through a large SQL query with a few dozen joins and left joins, alias, and recursions. He is mostly a front-end integrator and although he has been tinkering with SQL for years, he never really understood the basics. I realize that unless you have to write SQL, many front-end developers work from the API layer, where database interaction has been highly abstracted, and with only brief interactions, many do not realize how easy it is to know the fundamentals. I do not address subqueries, stored procedures or vendor-specific syntax. This example is just the foundation, yet everything builds up from it and can be broken down into it.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Don&#39;t Install cqlsh</title>
      <link>http://localhost:1313/dont-install-cqlsh/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/dont-install-cqlsh/</guid>
      <description>&lt;p&gt;We live in a world of process isolation and tools that make utilizing it extremely simple, with apps like &lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt; we can perform dependency management with &lt;strong&gt;dependency isolation&lt;/strong&gt;. As I am slowly becoming a fanboy of containerization, I look forward to the day when typing &lt;code&gt;ps&lt;/code&gt; on my local workstation or remote server is nearly synonymous with commands like &lt;code&gt;docker ps&lt;/code&gt; or &lt;code&gt;kubectl get services&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Case: &lt;strong&gt;Cassandra development and your local workstation.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
